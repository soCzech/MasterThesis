\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

This thesis approaches two key problems of video retrieval -- shot boundary detection and text-based search. 
We present TransNet V2, a network for the detection of common shot transitions, which tackles an important initial step of video analysis processes.
We address multiple issues of previous shot detectors and discuss in detail the training process as well as training data acquisition. We also reevaluate and compare ourselves to other recent approaches to shot boundary detection. The results show our method can outperform related works on multiple public benchmarks, and we believe it can be of great help in many video pre-processing pipelines of various multimedia search/analytics frameworks that require information about shots.

Further, we investigate text-to-visual matching systems utilized for text-based search in video collections. We experimentally prove that adding large Trans\-former-based text encoders improves the performance of such systems on some tasks if the whole encoder is trained.
All in all, we believe that both the shot boundary detector as well as our extension to the text-based search system show promising future research directions in both areas.
